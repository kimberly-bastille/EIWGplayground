# SOE Summary Stats Automation


```{r setup, include=FALSE, warning=FALSE, message=TRUE, echo=FALSE}

library(magrittr)

data <- ecodata::forage_index %>% 
  dplyr::group_by(Var, EPU)

data_big <- ecodata::forage_index
i = "GB"
j = "Annual Forage Fish Biomass Estimate"

#make mego dataset here
chl<- filter(Annual)


t1<- summarize_me_for_soe(data = data, EPU = unique(data$EPU) , Var = c(unique(data$Var)))

#issues: Can't handle 5+ NAs, doesn't do monthly
summarize_me_for_soe<- function(data, EPU, Var){

  summary_out <- NULL
  

  for(i in EPU){
    for(j in Var){
      print(i)
      print(j)

  dat <- d %>%
    dplyr::filter(EPU == i, 
           Var == j)  
  
  if(nrow(dat) == 0){
  next
    }
  
    dat <- dat %>% 
    dplyr::arrange(Time) %>%
    #Fill in time steps if there are missing values
    tidyr::complete(Time = tidyr::full_seq(min(Time):max(Time),1)) %>% 
    dplyr::rename(x = Time, y = Value) 
    

  data_all <- dat %>% 
    dplyr::summarise(mean = mean(y), 
                  sd = sd(y))
  
  data10 <- dat %>% 
   dplyr::filter(x %in% c(max(x):(max(x) - 9))) %>% 
    dplyr::summarise(mean10 = mean(y), 
                  sd10 = sd(y))

  
  summary_df <- data_all %>% 
    cbind(data10) %>% 
    dplyr::mutate(percent_change = (mean10 - mean)/mean *100)
  
  
    
  #Model fitting -------------------------------------------------------
  constant_norm <-
    nlme::gls(y ~ 1, data = dat, na.action = na.omit)
  
  constant_ar1 <-
    try(nlme::gls(y ~ 1, 
                  data = dat,
                  correlation = nlme::corAR1(form = ~x),
                  na.action = na.omit))
  if (class(constant_ar1) == "try-error"){
    return(best_lm <- data.frame(model = NA,
                                 aicc  = NA,
                                 coefs..Intercept = NA,
                                 coefs.time = NA,
                                 coefs.time2 = NA,
                                 pval = NA))}
  # Linear model with normal error
  linear_norm <- nlme::gls(y ~ x, data = dat, na.action = na.omit)
  # Linear model with AR1 error
  linear_ar1 <-try(nlme::gls(y ~ x,
                             data = dat,
                             correlation = nlme::corAR1(form = ~x),
                             na.action = na.omit))
  if (class(linear_ar1) == "try-error"){
    return(best_lm <- data.frame(model = NA,
                                 aicc  = NA,
                                 coefs..Intercept = NA,
                                 coefs.time = NA,
                                 coefs.time2 = NA,
                                 pval = NA))}
  # Polynomial model with normal error
  dat$x2 <- dat$x^2
  poly_norm <- nlme::gls(y ~ x + x2, data = dat, na.action = na.omit)
  # Polynomial model with AR1 error
  poly_ar1 <-try(nlme::gls(y ~ x + x2,
                           data = dat,
                           correlation = nlme::corAR1(form = ~x),
                           na.action = na.omit))
  if (class(poly_ar1) == "try-error"){
    return(best_lm <- data.frame(model = NA,
                                 aicc  = NA,
                                 coefs..Intercept = NA,
                                 coefs.time = NA,
                                 coefs.time2 = NA,
                                 pval = NA))}
  
  # Calculate AICs for all models
  df_aicc <- data.frame(model = c("poly_norm", "poly_ar1",
                                  "linear_norm", "linear_ar1"),
                        aicc  = c(AICcmodavg::AICc(poly_norm),
                                  AICcmodavg::AICc(poly_ar1),
                                  AICcmodavg::AICc(linear_norm),
                                  AICcmodavg::AICc(linear_ar1)),
                        coefs = rbind(coef(poly_norm),
                                      coef(poly_ar1),
                                      c(coef(linear_norm), NA),
                                      c(coef(linear_ar1),  NA)),
                        # Calculate overall signifiance (need to use
                                           # ML not REML for this)
                                           pval = c(anova(update(constant_norm, method = "ML"),
                                                          update(poly_norm, method = "ML"))$`p-value`[2],
                                                    anova(update(constant_ar1, method = "ML"),
                                                          update(poly_ar1, method = "ML"))$`p-value`[2],
                                                    anova(update(constant_norm, method = "ML"),
                                                          update(linear_norm, method = "ML"))$`p-value`[2],
                                                    anova(update(constant_ar1, method = "ML"),
                                                          update(linear_ar1, method = "ML"))$`p-value`[2]))
  best_lm <- df_aicc %>%
    dplyr::filter(aicc == min(aicc)) #Select model with lowest AICc
  if (best_lm$model == "poly_norm") {
    model <- poly_norm
    } else if (best_lm$model == "poly_ar1") {
      model <- poly_ar1
      } else if (best_lm$model == "linear_norm") {
        model <- linear_norm
        } else if (best_lm$model == "linear_ar1") {
          model <- linear_ar1
          }
  if (best_lm$pval < 0.05){
    model <- best_lm %>% 
      dplyr::select(model, pval) %>% 
      dplyr::mutate(trend = "true")
  }else{
    model <- data.frame(model = "None", 
                        pval = "Ignore",
                        trend = "false")
  }
  
  summary_df <- summary_df %>% 
    dplyr::mutate(indicator = j,
                  EPU = i, 
                  Max_Year = max(dat$x),
                  Min_Year = min(dat$x),
                  Timeseries_Length = Max_Year - Min_Year) %>% 
    cbind(model)
  
  summary_out <- summary_out %>% rbind(summary_df)
    }
  }
    
  return(summary_out)
}
                                           
```


## Purpose 

1) To make Brandon's life easier!! Automate and organize summary output for indicators to make it easier to update the website text. One-stop shop for SMEs?
2) Automate the process for visualization and plain language. Beginnings of PL Automation.
3) Look at indicator status and trends as a whole across regions and indicator group

## Data Sets
- WCR - trend 
- forage - no trend - Have to figure out group_by

### Summary output

<!-- ```{r, warning=FALSE, message=FALSE, echo=FALSE} -->

<!-- data<-ecodata::forage_anomaly %>% dplyr::filter(Var == "Forage_Mean",  -->
<!--                                                 EPU == "MAB") -->
<!-- forage<- ecodata::forage_anomaly %>% dplyr::filter(Var == "Forage_Mean") %>%  -->
<!--   dplyr::group_by(EPU) %>%  -->
<!--   summarize_me_for_soe() -->

<!-- forage -->


<!-- ``` -->


```{r, warning=FALSE, message=FALSE, echo=FALSE}

data<-ecodata::wcr
wcr<- summarize_me_for_soe(data)

DT::datatable(wcr)
# summarydf<- data.frame() #blank df to be populated
# 
# for (i in datalist) {
#   dat<-summarize_me_for_fun(i)
#   summarydf<-summarydf %>% rbind(dat) # Start edits here
# }
# 
# DT::datatable(summarydf)


```



## Next Steps

## Notes 7/26/23

Feedback from Sarah/Sean 
1) Long term trend gls
2) Short term trend lm
3) Variance change over time
4) Mean of times - SD
5) Mean of last 10 yrs - SD
6) Current status - % change from long term mean
7) length of time series 
8) Last year in time series
9) Change from last year - Sean
