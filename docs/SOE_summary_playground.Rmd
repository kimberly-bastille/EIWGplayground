# SOE Summary Stats Automation


```{r setup, include=FALSE, warning=FALSE, message=TRUE, echo=FALSE}

library(tidyverse)
dat = ecodata::forage_anomaly

data<-ecodata::wcr
test<- summarize_me_for_fun(ecodata::wcr)
#issues: Can't handle 5+ NAs, doesn't do monthly
summarize_me_for_fun<- function(data){

  data <- data %>%
    dplyr::arrange(Time) %>%
    #Fill in time steps if there are missing values
    tidyr::complete(Time = tidyr::full_seq(min(data$Time):max(data$Time),1)) %>% 
    dplyr::rename(x = Time, y = Value)

  #Model fitting -------------------------------------------------------
  constant_norm <-
    nlme::gls(y ~ 1, data = data, na.action = na.omit)
  
  constant_ar1 <-
    try(nlme::gls(y ~ 1, 
                  data = data,
                  correlation = nlme::corAR1(form = ~x),
                  na.action = na.omit))
  if (class(constant_ar1) == "try-error"){
    return(best_lm <- data.frame(model = NA,
                                 aicc  = NA,
                                 coefs..Intercept = NA,
                                 coefs.time = NA,
                                 coefs.time2 = NA,
                                 pval = NA))}
  # Linear model with normal error
  linear_norm <- nlme::gls(y ~ x, data = data, na.action = na.omit)
  # Linear model with AR1 error
  linear_ar1 <-try(nlme::gls(y ~ x,
                             data = data,
                             correlation = nlme::corAR1(form = ~x),
                             na.action = na.omit))
  if (class(linear_ar1) == "try-error"){
    return(best_lm <- data.frame(model = NA,
                                 aicc  = NA,
                                 coefs..Intercept = NA,
                                 coefs.time = NA,
                                 coefs.time2 = NA,
                                 pval = NA))}
  # Polynomial model with normal error
  data$x2 <- data$x^2
  poly_norm <- nlme::gls(y ~ x + x2, data = data, na.action = na.omit)
  # Polynomial model with AR1 error
  poly_ar1 <-try(nlme::gls(y ~ x + x2,
                           data = data,
                           correlation = nlme::corAR1(form = ~x),
                           na.action = na.omit))
  if (class(poly_ar1) == "try-error"){
    return(best_lm <- data.frame(model = NA,
                                 aicc  = NA,
                                 coefs..Intercept = NA,
                                 coefs.time = NA,
                                 coefs.time2 = NA,
                                 pval = NA))}
  
  # Calculate AICs for all models
  df_aicc <- data.frame(model = c("poly_norm", "poly_ar1",
                                  "linear_norm", "linear_ar1"),
                        aicc  = c(AICcmodavg::AICc(poly_norm),
                                  AICcmodavg::AICc(poly_ar1),
                                  AICcmodavg::AICc(linear_norm),
                                  AICcmodavg::AICc(linear_ar1)),
                        coefs = rbind(coef(poly_norm),
                                      coef(poly_ar1),
                                      c(coef(linear_norm), NA),
                                      c(coef(linear_ar1),  NA)),
                        # Calculate overall signifiance (need to use
                                           # ML not REML for this)
                                           pval = c(anova(update(constant_norm, method = "ML"),
                                                          update(poly_norm, method = "ML"))$`p-value`[2],
                                                    anova(update(constant_ar1, method = "ML"),
                                                          update(poly_ar1, method = "ML"))$`p-value`[2],
                                                    anova(update(constant_norm, method = "ML"),
                                                          update(linear_norm, method = "ML"))$`p-value`[2],
                                                    anova(update(constant_ar1, method = "ML"),
                                                          update(linear_ar1, method = "ML"))$`p-value`[2]))
  best_lm <- df_aicc %>%
    dplyr::filter(aicc == min(aicc)) #Select model with lowest AICc
  if (best_lm$model == "poly_norm") {
    model <- poly_norm
    } else if (best_lm$model == "poly_ar1") {
      model <- poly_ar1
      } else if (best_lm$model == "linear_norm") {
        model <- linear_norm
        } else if (best_lm$model == "linear_ar1") {
          model <- linear_ar1
          }
  if (best_lm$pval < 0.05){
    newtime <- seq(min(data$x), max(data$x), length.out=length(data$x))
    newdata <- data.frame(x = newtime,
                          x2 = newtime^2)
    lm_pred <- AICcmodavg::predictSE(model,
                                     newdata = newdata,
                                     se.fit = TRUE) #Get BLUE
    pred <- data.frame(x = data$x,
                       Value_pred = lm_pred$fit)
    
    dat_all <- data %>% dplyr::left_join(pred, by = "x") %>% 
      dplyr::rename(Time = x, 
                    Value = y)
    
  # mean_all <- data %>% 
  #   dplyr::group_by(Var, EPU) %>% 
  #   dplyr::summarise(mn = mean(Value, na.rm = TRUE), 
  #                    sd = sd(Value, na.rm = TRUE)) 
  # sum_dat <- data %>% 
  #   dplyr::group_by(Var, EPU) %>% 
  #   dplyr::filter(Time %in% c(max(Time):(max(Time) - 4))) %>% 
  #   dplyr::summarise(mn5 = mean(Value, na.rm=TRUE)) %>% 
  #   dplyr::left_join(mean_all, by = c("EPU", "Var")) %>% 
  #   dplyr::mutate(status = dplyr::case_when(mn5>mn ~ "greater than", 
  #                                              mn5<mn ~ "less than"))
  # 
  # sum_dat <- sum_dat %>% cbind(pred_sum_dat)
  #   return(sum_dat)
    return(dat_all)
                              }
                                           
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  # summary_df<- dat_all %>% 
  #   dplyr::group_by(region) %>% 
  #   dplyr::left_join(sum_dat, by = c("region")) %>%
  #   dplyr::mutate(#mn5 = mean(value, na.rm=TRUE),
  #                 delta = stats::predict(lm(year~value))[length(stats::predict(lm(year~value)))] - stats::predict(lm(year~value))[1], 
  #                 Z = abs(delta)-(sd(value, na.rm=TRUE)), 
  #                 trend = ifelse(Z > 0, paste0("significantly"), paste0("")), 
  #                 gauge = round(stats::ecdf(value)(mn5) *100)) %>% 
  #   
  #   dplyr::left_join(dat_all2, by = c("region", "title" ,"y_lab")) %>% 
  #   dplyr::summarise(indicator = unique(title), 
  #                    region = unique(region), 
  #                    #year = unique(year),
  #                    mn = unique(mn), 
  #                    mn5 = unique(mn5),
  #                    status = unique(status), 
  #                    trend = unique(trend), 
  #                    delta = unique(delta), 
  #                    Z = unique(Z),
  #                    gauge = unique(gauge))  
  #   
  # 
  # return(summary_df)
}


# plain_language<- function(data){
#   plain<-  summarydf %>% 
#     group_by(region, title) %>% 
#     dplyr::mutate(PlainLanguage = c(paste("this figure shows", title, " in ", y_lab, "ranging from ", min(value), "to", max(value), 
#                                           "from", min(year), "to ", max(year),". The overall trend is ", trend, 
#                                           "and the last five years are ", status, "the time series mean of ", mn, ".")))
#   return(plain)
# 
# }
```


## Purpose 

1) To make Brandon's life easier!! Automate and organize summary output for indicators to make it easier to update the website text. One-stop shop for SMEs?
2) Automate the process for visualization and plain language. Beginnings of PL Automation.
3) Look at indicator status and trends as a whole across regions and indicator group

## Data Sets
- WCR
### Summary output
```{r, warning=FALSE, message=FALSE, echo=FALSE}

datalist <- c(ecodata::wcr)

summarydf<- data.frame() #blank df to be populated

for (i in datalist) {
  dat<-summarize_me_for_fun(i)
  summarydf<-summarydf %>% rbind(dat) # Start edits here
}

DT::datatable(summarydf)


```






## Next Steps

